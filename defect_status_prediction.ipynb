{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import svm, tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score\n",
    "import time\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_file (filename):\n",
    "    df = pd.read_csv(filename)  # read the csv file\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_PCA(train, test):\n",
    "    # Since PCA is effected by scale, we need to scale the features in the data before applying PCA\n",
    "    scaler = StandardScaler()\n",
    "    # Fit on training set only.\n",
    "    scaler.fit(train)\n",
    "    # Apply transform to both the training set and the test set.\n",
    "    train = scaler.transform(train)\n",
    "    test = scaler.transform(test)\n",
    "\n",
    "    # Make an instance of the Model\n",
    "    pca = PCA(0.95) #  choose the minimum number of principal components such that 95% of the variance is retained.\n",
    "    # We are fitting PCA on the training set only.\n",
    "    pca.fit(train)\n",
    "    #print (\"Number of selected components: \", pca.n_components_)\n",
    "    #print (pd.DataFrame(pca.components_))\n",
    "    \n",
    "    # Apply the mapping (transform) to both the training set and the test set\n",
    "    #print(\"Before applying PCA train set size: \", train.shape)\n",
    "    #print(\"Before applying PCA test set size: \", test.shape)\n",
    "    train = pca.transform(train)\n",
    "    test = pca.transform(test)\n",
    "    #print(\"After applying PCA train set size: \", train.shape)\n",
    "    #print(\"After applying PCA test set size: \", test.shape)\n",
    "    return train,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perfrom_CART(train, test, train_label, test_label):\n",
    "    clf = tree.DecisionTreeClassifier(criterion='gini', splitter='best', \n",
    "                                      min_samples_split = 2, min_weight_fraction_leaf=0.0)\n",
    "    start = time.perf_counter()\n",
    "    clf.fit(train, train_label)\n",
    "    end = time.perf_counter()\n",
    "    fit_time = end - start\n",
    "    start = time.perf_counter()\n",
    "    predicted_label = clf.predict(test)\n",
    "    end = time.perf_counter()\n",
    "    predict_time = end - start\n",
    "    recall, precision, f1 = measure_performance(test_label, predicted_label)\n",
    "    return recall, precision, f1, fit_time, predict_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perfrom_KNN(train, test, train_label, test_label):\n",
    "    clf = KNeighborsClassifier(n_neighbors=5, weights='distance')\n",
    "    start = time.perf_counter()\n",
    "    clf.fit(train, train_label)\n",
    "    end = time.perf_counter()\n",
    "    fit_time = end - start\n",
    "    start = time.perf_counter()\n",
    "    predicted_label = clf.predict(test)\n",
    "    end = time.perf_counter()\n",
    "    predict_time = end - start\n",
    "    recall, precision, f1 = measure_performance(test_label, predicted_label)\n",
    "    return recall, precision, f1, fit_time, predict_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perfrom_SVM(train, test, train_label, test_label):\n",
    "    clf = svm.SVC(gamma='auto', C = 20.0, kernel='rbf')\n",
    "    start = time.perf_counter()\n",
    "    clf.fit(train, train_label)\n",
    "    end = time.perf_counter()\n",
    "    fit_time = end - start\n",
    "    start = time.perf_counter()\n",
    "    predicted_label = clf.predict(test)\n",
    "    end = time.perf_counter()\n",
    "    predict_time = end - start\n",
    "    recall, precision, f1 = measure_performance(test_label, predicted_label)\n",
    "    return recall, precision, f1, fit_time, predict_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perfrom_NB(train, test, train_label, test_label):\n",
    "    clf = GaussianNB()\n",
    "    start = time.perf_counter()\n",
    "    clf.fit(train, train_label)\n",
    "    end = time.perf_counter()\n",
    "    fit_time = end - start\n",
    "    start = time.perf_counter()\n",
    "    predicted_label = clf.predict(test)\n",
    "    end = time.perf_counter()\n",
    "    predict_time = end - start\n",
    "    recall, precision, f1 = measure_performance(test_label, predicted_label)\n",
    "    return recall, precision, f1, fit_time, predict_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perfrom_RF(train, test, train_label, test_label):\n",
    "    clf = RandomForestClassifier(n_estimators=10, criterion='gini')\n",
    "    start = time.perf_counter()\n",
    "    clf.fit(train, train_label)\n",
    "    end = time.perf_counter()\n",
    "    fit_time = end - start\n",
    "    start = time.perf_counter()\n",
    "    predicted_label = clf.predict(test)\n",
    "    end = time.perf_counter()\n",
    "    predict_time = end - start\n",
    "    recall, precision, f1 = measure_performance(test_label, predicted_label)\n",
    "    return recall, precision, f1, fit_time, predict_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_performance(true_label, predicted_label):   \n",
    "    precision = recall = f1 = np.zeros(2, dtype=np.float32)\n",
    "    report = classification_report(true_label, predicted_label)\n",
    "    precision = precision_score(true_label, predicted_label, average=None, labels=[0,1])\n",
    "    recall = recall_score(true_label, predicted_label, average=None, labels=[0,1])\n",
    "    f1 = f1_score(true_label, predicted_label, average=None, labels=[0,1])\n",
    "    return recall, precision, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_cv(data, true_label):\n",
    "    # 10 fold cv\n",
    "    kf = KFold(n_splits=10, shuffle = True, random_state = 7)\n",
    "\n",
    "    cv_recall_DT = []\n",
    "    cv_precision_DT = []\n",
    "    cv_f1_DT = []\n",
    "    cv_fit_time_DT = []\n",
    "    cv_predict_time_DT = []\n",
    "    \n",
    "    cv_recall_KNN = []\n",
    "    cv_precision_KNN = []\n",
    "    cv_f1_KNN = []\n",
    "    cv_fit_time_KNN = []\n",
    "    cv_predict_time_KNN = []\n",
    "    \n",
    "    cv_recall_SVM = []\n",
    "    cv_precision_SVM = []\n",
    "    cv_f1_SVM = []\n",
    "    cv_fit_time_SVM = []\n",
    "    cv_predict_time_SVM = []\n",
    "    \n",
    "    cv_recall_NB = []\n",
    "    cv_precision_NB = []\n",
    "    cv_f1_NB = []\n",
    "    cv_fit_time_NB = []\n",
    "    cv_predict_time_NB = []\n",
    "    \n",
    "    cv_recall_RF = []\n",
    "    cv_precision_RF = []\n",
    "    cv_f1_RF = []\n",
    "    cv_fit_time_RF =[]\n",
    "    cv_predict_time_RF = []\n",
    "\n",
    "\n",
    "    for train_index, test_index in kf.split(data):\n",
    "        train, test = data.iloc[train_index], data.iloc[test_index]\n",
    "        train_label, test_label = true_label[train_index], true_label[test_index]\n",
    "\n",
    "        train, test = apply_PCA(train, test)\n",
    "\n",
    "        recall, precision, f1, fit_time, predict_time = perfrom_CART(train, test, train_label, test_label)\n",
    "        cv_recall_DT.append(recall)\n",
    "        cv_precision_DT.append(precision)\n",
    "        cv_f1_DT.append(f1)\n",
    "        cv_fit_time_DT.append(fit_time)\n",
    "        cv_predict_time_DT.append(predict_time)\n",
    "\n",
    "        recall, precision, f1, fit_time, predict_time = perfrom_KNN(train, test, train_label, test_label)\n",
    "        cv_recall_KNN.append(recall)\n",
    "        cv_precision_KNN.append(precision)\n",
    "        cv_f1_KNN.append(f1)\n",
    "        cv_fit_time_KNN.append(fit_time)\n",
    "        cv_predict_time_KNN.append(predict_time)\n",
    "\n",
    "        recall, precision, f1, fit_time, predict_time = perfrom_SVM(train, test, train_label, test_label)\n",
    "        cv_recall_SVM.append(recall)\n",
    "        cv_precision_SVM.append(precision)\n",
    "        cv_f1_SVM.append(f1)\n",
    "        cv_fit_time_SVM.append(fit_time)\n",
    "        cv_predict_time_SVM.append(predict_time)\n",
    "\n",
    "        recall, precision, f1, fit_time, predict_time = perfrom_NB(train, test, train_label, test_label)\n",
    "        cv_recall_NB.append(recall)\n",
    "        cv_precision_NB.append(precision)\n",
    "        cv_f1_NB.append(f1)\n",
    "        cv_fit_time_NB.append(fit_time)\n",
    "        cv_predict_time_NB.append(predict_time)\n",
    "\n",
    "        recall, precision, f1, fit_time, predict_time = perfrom_RF(train, test, train_label, test_label)\n",
    "        cv_recall_RF.append(recall)\n",
    "        cv_precision_RF.append(precision)\n",
    "        cv_f1_RF.append(f1)\n",
    "        cv_fit_time_RF.append(fit_time)\n",
    "        cv_predict_time_RF.append(predict_time)\n",
    "\n",
    "        \n",
    "    recall_DT = np.mean(cv_recall_DT, axis= 0)\n",
    "    precision_DT = np.mean(cv_precision_DT, axis= 0)\n",
    "    f1_DT = np.mean(cv_f1_DT, axis= 0)\n",
    "    fit_time_DT = np.mean(cv_fit_time_DT)\n",
    "    predict_time_DT = np.mean(cv_predict_time_DT)\n",
    "\n",
    "    recall_KNN = np.mean(cv_recall_KNN, axis= 0)\n",
    "    precision_KNN = np.mean(cv_precision_KNN, axis= 0)\n",
    "    f1_KNN = np.mean(cv_f1_KNN, axis= 0)\n",
    "    fit_time_KNN = np.mean(cv_fit_time_KNN)\n",
    "    predict_time_KNN = np.mean(cv_predict_time_KNN)\n",
    "    \n",
    "    recall_SVM = np.mean(cv_recall_SVM, axis= 0)\n",
    "    precision_SVM = np.mean(cv_precision_SVM, axis= 0)\n",
    "    f1_SVM =  np.mean(cv_f1_SVM, axis= 0)\n",
    "    fit_time_SVM = np.mean(cv_fit_time_SVM)\n",
    "    predict_time_SVM = np.mean(cv_predict_time_SVM)\n",
    "    \n",
    "    recall_NB = np.mean(cv_recall_NB, axis= 0)\n",
    "    precision_NB = np.mean(cv_precision_NB, axis= 0)\n",
    "    f1_NB = np.mean(cv_f1_NB, axis= 0)\n",
    "    fit_time_NB = np.mean(cv_fit_time_NB)\n",
    "    predict_time_NB = np.mean(cv_predict_time_NB)\n",
    "    \n",
    "    recall_RF = np.mean(cv_recall_RF, axis= 0)\n",
    "    precision_RF = np.mean(cv_precision_RF, axis= 0)\n",
    "    f1_RF = np.mean(cv_f1_RF, axis= 0)\n",
    "    fit_time_RF = np.mean(cv_fit_time_RF)\n",
    "    predict_time_RF = np.mean(cv_predict_time_RF)\n",
    "    \n",
    "    return recall_DT, precision_DT, f1_DT, fit_time_DT, predict_time_DT, recall_KNN, precision_KNN, f1_KNN,\\\n",
    "    fit_time_KNN, predict_time_KNN, recall_SVM, precision_SVM, f1_SVM, fit_time_SVM, predict_time_SVM, recall_NB,\\\n",
    "    precision_NB, f1_NB, fit_time_NB, predict_time_NB, recall_RF, precision_RF, f1_RF, fit_time_RF, predict_time_RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeated_test(data, true_label):\n",
    "    repeated_recall_DT = []\n",
    "    repeated_precision_DT = []\n",
    "    repeated_f1_DT = []\n",
    "    repeated_fit_time_DT = []\n",
    "    repeated_predict_time_DT = []\n",
    "    \n",
    "    repeated_recall_KNN = []\n",
    "    repeated_precision_KNN = []\n",
    "    repeated_f1_KNN = []\n",
    "    repeated_fit_time_KNN = []\n",
    "    repeated_predict_time_KNN = []\n",
    "    \n",
    "    repeated_recall_SVM = []\n",
    "    repeated_precision_SVM = []\n",
    "    repeated_f1_SVM = []\n",
    "    repeated_fit_time_SVM = []\n",
    "    repeated_predict_time_SVM = []\n",
    "    \n",
    "    repeated_recall_NB = []\n",
    "    repeated_precision_NB = []\n",
    "    repeated_f1_NB = []\n",
    "    repeated_fit_time_NB = []\n",
    "    repeated_predict_time_NB = []\n",
    "    \n",
    "    repeated_recall_RF = []\n",
    "    repeated_precision_RF = []\n",
    "    repeated_f1_RF = []\n",
    "    repeated_fit_time_RF = []\n",
    "    repeated_predict_time_RF = []\n",
    "    \n",
    "    recall_DT= precision_DT= f1_DT= fit_time_DT= predict_time_DT= recall_KNN= precision_KNN= f1_KNN=\\\n",
    "    fit_time_KNN= predict_time_KNN= recall_SVM = precision_SVM= f1_SVM= fit_time_SVM= predict_time_SVM\\\n",
    "    = recall_NB= precision_NB= f1_NB= fit_time_NB= predict_time_NB= recall_RF= precision_RF= f1_RF\\\n",
    "    = fit_time_RF= predict_time_RF = 0\n",
    "    \n",
    "    for i in range(10):\n",
    "        recall_DT, precision_DT, f1_DT, fit_time_DT, predict_time_DT, recall_KNN, precision_KNN, f1_KNN,\\\n",
    "        fit_time_KNN, predict_time_KNN, recall_SVM, precision_SVM, f1_SVM, fit_time_SVM, predict_time_SVM,\\\n",
    "        recall_NB, precision_NB, f1_NB, fit_time_NB, predict_time_NB, recall_RF, precision_RF, f1_RF, fit_time_RF,\\\n",
    "        predict_time_RF = kfold_cv(data, true_label)\n",
    "        \n",
    "        repeated_recall_DT.append(recall_DT)\n",
    "        repeated_precision_DT.append(precision_DT)\n",
    "        repeated_f1_DT.append(f1_DT)\n",
    "        repeated_fit_time_DT.append(fit_time_DT) \n",
    "        repeated_predict_time_DT.append(predict_time_DT)\n",
    "\n",
    "        repeated_recall_KNN.append(recall_KNN)\n",
    "        repeated_precision_KNN.append(precision_KNN)\n",
    "        repeated_f1_KNN.append(f1_KNN)\n",
    "        repeated_fit_time_KNN.append(fit_time_KNN) \n",
    "        repeated_predict_time_KNN.append(predict_time_KNN)\n",
    "\n",
    "        repeated_recall_SVM.append(recall_SVM)\n",
    "        repeated_precision_SVM.append(precision_SVM)\n",
    "        repeated_f1_SVM.append(f1_SVM)\n",
    "        repeated_fit_time_SVM.append(fit_time_SVM) \n",
    "        repeated_predict_time_SVM.append(predict_time_SVM)\n",
    "        \n",
    "        repeated_recall_NB.append(recall_NB)\n",
    "        repeated_precision_NB.append(precision_NB)\n",
    "        repeated_f1_NB.append(f1_NB)\n",
    "        repeated_fit_time_NB.append(fit_time_NB) \n",
    "        repeated_predict_time_NB.append(predict_time_NB)\n",
    "        \n",
    "        repeated_recall_RF.append(recall_RF)\n",
    "        repeated_precision_RF.append(precision_RF)\n",
    "        repeated_f1_RF.append(f1_RF)\n",
    "        repeated_fit_time_RF.append(fit_time_RF) \n",
    "        repeated_predict_time_RF.append(predict_time_RF)\n",
    "        \n",
    "    print(\"-------DT-------\")\n",
    "    print(\"Recall:\", np.median(repeated_recall_DT, axis= 0))\n",
    "    print(\"Precision:\", np.median(repeated_precision_DT, axis= 0))\n",
    "    print(\"f1 score:\", np.median(repeated_f1_DT, axis= 0))\n",
    "    print(\"Fit time:\", np.median(repeated_fit_time_DT))\n",
    "    print(\"Predict time:\", np.median(repeated_predict_time_DT))\n",
    "\n",
    "    print(\"-------KNN-------\")\n",
    "    print(\"Recall:\", np.median(repeated_recall_KNN, axis= 0))\n",
    "    print(\"Precision:\", np.median(repeated_precision_KNN, axis= 0))\n",
    "    print(\"f1 score:\", np.median(repeated_f1_KNN, axis= 0))\n",
    "    print(\"Fit time:\", np.median(repeated_fit_time_KNN))\n",
    "    print(\"Predict time:\", np.median(repeated_predict_time_KNN))\n",
    "\n",
    "    print(\"-------SVM-------\")\n",
    "    print(\"Recall:\", np.median(repeated_recall_SVM, axis= 0))\n",
    "    print(\"Precision:\", np.median(repeated_precision_SVM, axis= 0))\n",
    "    print(\"f1 score:\", np.median(repeated_f1_SVM, axis= 0))\n",
    "    print(\"Fit time:\", np.median(repeated_fit_time_SVM))\n",
    "    print(\"Predict time:\", np.median(repeated_predict_time_SVM))\n",
    "    \n",
    "    print(\"-------NB-------\")\n",
    "    print(\"Recall:\", np.median(repeated_recall_NB, axis= 0))\n",
    "    print(\"Precision:\", np.median(repeated_precision_NB, axis= 0))\n",
    "    print(\"f1 score:\", np.median(repeated_f1_NB, axis= 0))\n",
    "    print(\"Fit time:\", np.median(repeated_fit_time_NB))\n",
    "    print(\"Predict time:\", np.median(repeated_predict_time_NB))\n",
    "    \n",
    "    print(\"-------RF-------\")\n",
    "    print(\"Recall:\", np.median(repeated_recall_RF, axis= 0))\n",
    "    print(\"Precision:\", np.median(repeated_precision_RF, axis= 0))\n",
    "    print(\"f1 score:\", np.median(repeated_f1_RF, axis= 0))\n",
    "    print(\"Fit time:\", np.median(repeated_fit_time_RF))\n",
    "    print(\"Predict time:\", np.median(repeated_predict_time_RF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcFeatureImp(feature_vec, label_vec, feature_names_param, repeat=10):\n",
    "    header_str, output= '', ''\n",
    "    for name_ in feature_names_param:\n",
    "        header_str = header_str + name_ + ','\n",
    "    theRndForestModel = RandomForestClassifier()\n",
    "    theRndForestModel.fit(feature_vec, label_vec)\n",
    "    feat_imp_vector=theRndForestModel.feature_importances_\n",
    "\n",
    "    for ind_ in range(repeat):\n",
    "        for imp_vec_index in range(len(feat_imp_vector)):\n",
    "            feat_imp_val = round(feat_imp_vector[imp_vec_index], 5)\n",
    "            output = output +  str(feat_imp_val) + ','\n",
    "        output = output + '\\n'\n",
    "    output_status = header_str + '\\n' + output\n",
    "    #print (\"Feature importance: \", output_status)\n",
    "    \n",
    "    feat_imp_vector=list(feat_imp_vector)\n",
    "    sorted_feat_imp_vector= [x_ for x_ in feat_imp_vector]\n",
    "    sorted_feat_imp_vector.sort(reverse=True)\n",
    "    \n",
    "    sorted_feature_name = []\n",
    "    for feat_imp_val in sorted_feat_imp_vector:\n",
    "        feat_index = feat_imp_vector.index(feat_imp_val) \n",
    "        sorted_feature_name.append(feature_names_param[feat_index])\n",
    "        \n",
    "    print (\"sorted feature names: \", sorted_feature_name)\n",
    "    print (\"sorted feature importance: \", sorted_feat_imp_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial process data shape:  (6477, 12)\n",
      "Initial code data shape:  (6396, 10)\n",
      "-------DT-------\n",
      "Recall: [0.97260162 0.16815768]\n",
      "Precision: [0.95102488 0.27198234]\n",
      "f1 score: [0.96166789 0.20185101]\n",
      "Fit time: 0.017225281299977267\n",
      "Predict time: 0.00019404299997631823\n",
      "-------KNN-------\n",
      "Recall: [0.98293632 0.17232392]\n",
      "Precision: [0.95172336 0.37657808]\n",
      "f1 score: [0.96704077 0.2301127 ]\n",
      "Fit time: 0.0021490012999834107\n",
      "Predict time: 0.0027151943999797366\n",
      "-------SVM-------\n",
      "Recall: [0.99949884 0.00533428]\n",
      "Precision: [0.94351125 0.15      ]\n",
      "f1 score: [0.97068246 0.01025641]\n",
      "Fit time: 0.6445152836499914\n",
      "Predict time: 0.009430811400011407\n",
      "-------NB-------\n",
      "Recall: [0.97763084 0.01097816]\n",
      "Precision: [0.94263258 0.03095238]\n",
      "f1 score: [0.95976978 0.01611714]\n",
      "Fit time: 0.0013720812999736154\n",
      "Predict time: 0.00021025885000653944\n",
      "-------RF-------\n",
      "Recall: [0.98310528 0.16710024]\n",
      "Precision: [0.95158387 0.36994817]\n",
      "f1 score: [0.96701135 0.2248196 ]\n",
      "Fit time: 0.056368819049998825\n",
      "Predict time: 0.0017435367000302904\n",
      "sorted feature names:  ['AVGCHNG', 'SCTR', 'OWN', 'COMM', 'DEV', 'MINOR']\n",
      "sorted feature importance:  [0.4193771026141494, 0.3812985440907755, 0.08660002179148026, 0.0865785899582829, 0.01564794746495468, 0.010497794080357215]\n"
     ]
    }
   ],
   "source": [
    "process_data = pd.read_csv('..//FINAL_PROCESS_METRICS.csv') \n",
    "print(\"Initial process data shape: \", process_data.shape)\n",
    "code_data = pd.read_csv('..//FINAL_CODE_METRICS.csv') \n",
    "print(\"Initial code data shape: \", code_data.shape)\n",
    "\n",
    "actual_process_file_name = process_data['file_']\n",
    "actual_code_file_name = code_data['FILE_PATH']\n",
    "\n",
    "formatted_process_file_name = []\n",
    "formatted_code_file_name = []   \n",
    "\n",
    "for item in actual_process_file_name:\n",
    "    formatted_process_file_name.append(re.split('V5/', item)[1]) \n",
    "for item in actual_code_file_name:\n",
    "    formatted_code_file_name.append(re.split('V5/', item)[1])\n",
    "    \n",
    "process_data['file_'] =  formatted_process_file_name   \n",
    "code_data['FILE_PATH'] =  formatted_code_file_name   \n",
    "    \n",
    "formatted_process_file_name = set(line.strip() for line in formatted_process_file_name)\n",
    "formatted_code_file_name = set(line.strip() for line in formatted_code_file_name)    \n",
    "    \n",
    "common_data = []\n",
    "true_label = []\n",
    "\n",
    "for common_entry in formatted_process_file_name & formatted_code_file_name:\n",
    "    if common_entry:\n",
    "        process_index =  process_data[process_data['file_'] == common_entry].index[0]\n",
    "        common_data.append(process_data.loc[process_index])\n",
    "        true_label.append(process_data.iloc[process_index]['defect_status'])\n",
    "\n",
    "data = pd.DataFrame(common_data)\n",
    "data = data.reset_index(drop=True)\n",
    "data = data.drop(columns=['org', 'file_', 'FILE_PATH', 'MT_PP', 'MT_NON_PP', 'defect_status'])\n",
    "\n",
    "true_label = np.array(true_label)\n",
    "\n",
    "repeated_test(data, true_label) #repeat kfold 10 times and report avarage performance\n",
    "\n",
    "columns_name = list(data.columns.values) # read all column names\n",
    "calcFeatureImp(data, true_label, columns_name) # find feature importance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
